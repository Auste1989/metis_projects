{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration, Cleanup and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:27.082415Z",
     "start_time": "2018-08-20T20:56:27.071570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:13:12.474991Z",
     "start_time": "2018-08-20T21:13:12.470650Z"
    }
   },
   "outputs": [],
   "source": [
    "#Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#SQL related\n",
    "import sqlite3\n",
    "import pandas.io.sql as pd_sql\n",
    "\n",
    "#API related\n",
    "import requests\n",
    "\n",
    "#Preprocessing\n",
    "import re\n",
    "from geotext import GeoText\n",
    "from calendar import month_name\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Sentiment analysis\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.625682Z",
     "start_time": "2018-08-20T20:56:28.621927Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting up for working with SQLite database\n",
    "sqlite_file = '/Users/auste_m/ds/metis/metisgh/github/metis_projects/Customer_Review_Sentiment_Analysis/Datasets/twitter-airline-sentiment/database.sqlite'\n",
    "\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.632673Z",
     "start_time": "2018-08-20T20:56:28.628125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the table are: \n",
      "['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline', 'airline_sentiment_gold', 'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord', 'tweet_created', 'tweet_location', 'user_timezone']\n",
      "\n",
      "Preview of one of the rows in the table:\n",
      "(567588278875213824, 'neutral', 1, '', '', 'Delta', '', 'JetBlueNews', '', 0, \"@JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Greenfield Daily Reporter http://t.co/LM3opxkxch\", '', '2015-02-16 23:36:05 -0800', 'USA', 'Sydney')\n"
     ]
    }
   ],
   "source": [
    "#Check one of the rows in the table\n",
    "preview = cursor.execute(\"SELECT * FROM Tweets LIMIT 20\")\n",
    "columns = [column[0] for column in preview.description]\n",
    "print('The columns of the table are:' + ' \\n' + str(columns) + '\\n')\n",
    "print('Preview of one of the rows in the table:' + '\\n' + str(preview.fetchone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.799117Z",
     "start_time": "2018-08-20T20:56:28.634411Z"
    }
   },
   "outputs": [],
   "source": [
    "#Retrieve relevant information from Tweets table in SQLite database and store them in a pandas dataframe\n",
    "query = \"\"\"SELECT airline, retweet_count, text as 'tweet' \n",
    "            FROM Tweets\"\"\"\n",
    "\n",
    "\n",
    "tweets_df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.827459Z",
     "start_time": "2018-08-20T20:56:28.801209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14485 entries, 0 to 14484\n",
      "Data columns (total 3 columns):\n",
      "airline          14485 non-null object\n",
      "retweet_count    14485 non-null int64\n",
      "tweet            14485 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 339.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue's new CEO seeks the right balance to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united yes. We waited in line for almost an h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the we got into the gate at IAH on tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir its cool that my bags take a bit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline  retweet_count                                              tweet\n",
       "0      Delta              0  @JetBlue's new CEO seeks the right balance to ...\n",
       "1      Delta              0  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...\n",
       "2     United              0  @united yes. We waited in line for almost an h...\n",
       "3     United              0  @united the we got into the gate at IAH on tim...\n",
       "4  Southwest              0  @SouthwestAir its cool that my bags take a bit..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "print(tweets_df.info())\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put aside a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.835916Z",
     "start_time": "2018-08-20T20:56:28.829199Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_test = tweets_df[10000:12000]\n",
    "tweets_train = tweets_df[:10000]\n",
    "tweets_train = tweets_train.append(tweets_df[12000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:28.839856Z",
     "start_time": "2018-08-20T20:56:28.837828Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tweets_train.info()\n",
    "# tweets_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's gather airport information from an external API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:30.709950Z",
     "start_time": "2018-08-20T20:56:28.842048Z"
    }
   },
   "outputs": [],
   "source": [
    "#First need to get global airport database through an API request \n",
    "airport_db_url = 'https://aviation-edge.com/api/public/airportDatabase?key=42e87b-a2f1be-c446fa-06d7a2-012f14'\n",
    "get_response = requests.get(airport_db_url)\n",
    "airport_db = get_response.json()\n",
    "\n",
    "#Then I need to extract the information that is relevant to me (airport names and codes)\n",
    "airport_info = []\n",
    "\n",
    "for airport in airport_db:\n",
    "    airport_info.append(airport['codeIataAirport'])\n",
    "    airport_info.append(airport['nameAirport'])\n",
    "\n",
    "#Test that results make sense\n",
    "# if 'IAH' in airport_codes:\n",
    "#     print(airport_db[airport_codes.index('IAH')])\n",
    "# else:\n",
    "#     print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:30.715921Z",
     "start_time": "2018-08-20T20:56:30.711923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20102"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airport_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's set up some helped functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:30.733112Z",
     "start_time": "2018-08-20T20:56:30.718120Z"
    }
   },
   "outputs": [],
   "source": [
    "#helper function to remove stuff from tweets\n",
    "\n",
    "def remove_airline(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with hashtag removed.\"\"\"\n",
    "    pattern1 = re.compile('@[A-Za-z]+\\w')\n",
    "    new_string = string\n",
    "    try:\n",
    "        all_airlines = pattern1.findall(new_string)\n",
    "        for airline in all_airlines:\n",
    "            new_string = re.sub(airline, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "def remove_hashtag(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with hashtag removed.\"\"\"\n",
    "    pattern2 = re.compile('#\\w+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        all_hashtags = pattern2.findall(new_string)\n",
    "        for hashtag in all_hashtags:\n",
    "            new_string = re.sub(hashtag, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_code(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with any capital letter & digit combination text removed.\"\"\"\n",
    "    pattern3 = re.compile('[A-Z]?\\d+[A-Z]+')\n",
    "    pattern4 = re.compile('\\d+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        codes = pattern3.findall(new_string)\n",
    "        codes.extend(pattern4.findall(new_string))\n",
    "        for elem in codes:\n",
    "            new_string = re.sub(elem, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "    \n",
    "    \n",
    "def remove_url(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with any urls removed removed.\"\"\"\n",
    "    pattern5 = re.compile('http://t.co/\\w+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        urls = pattern5.findall(new_string)\n",
    "        for url in urls:\n",
    "            new_string = re.sub(url, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_location(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with location information removed.\"\"\"\n",
    "    new_string = string\n",
    "    geo_loc = GeoText(string)\n",
    "    locations = []\n",
    "    if geo_loc.cities != []:\n",
    "        locations.extend(geo_loc.cities)\n",
    "    if geo_loc.countries != []:\n",
    "        locations.extend(geo_loc.countries)\n",
    "    try:\n",
    "        for loc in locations:\n",
    "            new_string = re.sub(loc, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "    \n",
    "    \n",
    "def remove_month(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with month information removed.\"\"\"\n",
    "    new_string = string\n",
    "    all_months = month_name[1:]\n",
    "    try:\n",
    "        for word in string.split():\n",
    "            if word in all_months:\n",
    "                new_string = re.sub(word, '', new_string)\n",
    "            else:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with emojis removed.\"\"\"    \n",
    "    pattern6 = re.compile(\"[\"\n",
    "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    new_string = string\n",
    "    try:\n",
    "        emojis = pattern6.findall(new_string)\n",
    "        for emoji in emojis:\n",
    "            new_string = re.sub(emoji, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def vectorize_emoji(string):\n",
    "    \"\"\"Takes a string and picks put all emojis\n",
    "    Returns a sentiment associated with the emojis.\"\"\"\n",
    "    emoji_sentiment = string.emoji2vec()\n",
    "    return emoji_sentiment\n",
    "\n",
    "def remove_airport(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with airport codes removed.\"\"\" \n",
    "    new_string = string\n",
    "    try:\n",
    "        for word in string.split():\n",
    "            if word in airport_info:\n",
    "                new_string = re.sub(word, '', new_string)\n",
    "            else:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def get_Vader_sentiment(string):\n",
    "    \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "    Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "    SIA = SentimentIntensityAnalyzer()\n",
    "    total_score = SIA.polarity_scores(string)\n",
    "    if total_score['compound'] < -0.05:\n",
    "        sentiment = 'negative'\n",
    "    elif total_score['compound'] >= 0.2:\n",
    "        sentiment = 'positive'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    polarity = total_score['compound']\n",
    "    return (sentiment, polarity)\n",
    "\n",
    "\n",
    "def get_TextBlob_sentiment(string):\n",
    "    \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "    Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "    sentiment_all = TextBlob(string).sentiment\n",
    "    if sentiment_all.polarity < -0.05:\n",
    "        sentiment = 'negative'\n",
    "    elif sentiment_all.polarity >= 0.2:\n",
    "        sentiment = 'positive'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    polarity = sentiment_all.polarity\n",
    "    return (sentiment, polarity)\n",
    "\n",
    "\n",
    "# def get_sentiment(string):\n",
    "#     \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "#     Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "#     #API stuff\n",
    "#     sentiment_API_url = 'https://japerk-text-processing.p.mashape.com/sentiment/'\n",
    "#     sentiment_API_response = requests.post(sentiment_API_url,\n",
    "#                                           data={\n",
    "#                                             \"language\": \"english\",\n",
    "#                                             \"text\": test_tweet}\n",
    "#                                               ,\n",
    "#                                           headers={\n",
    "#                                             \"X-Mashape-Key\": \"3hN4k8H8Brmsh0Hp4sTefboY6vHpp1qZZ3jjsnvlGiMsNSK59o\",\n",
    "#                                             \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#                                             \"Accept\": \"application/json\"}\n",
    "#                                           )\n",
    "\n",
    "#     sentiment_all = sentiment_API_response.json()\n",
    "#     sentiment = sentiment_all['label']\n",
    "#     neg_prob = sentiment_all['probability']['neg']\n",
    "#     return (sentiment, neg_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T20:56:35.122284Z",
     "start_time": "2018-08-20T20:56:30.734926Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tweet: '@SouthwestAir need to learn how to treat people with respect and just a little dignity. #FAIL '\n",
      "Scores using TextBlob default Sentiment(polarity=-0.34375, subjectivity=0.39999999999999997)\n",
      "Scores using TextBlob Naive Bayes classifier Sentiment(classification='pos', p_pos=0.7744402760303103, p_neg=0.22555972396969037)\n",
      "Scores using Vader {'neg': 0.0, 'neu': 0.594, 'pos': 0.406, 'compound': 0.8024}\n"
     ]
    }
   ],
   "source": [
    "#Are the tweets positive or negative (tried TextBlob.sentiment, TextBlob.NaiveBayesAnalyzer, nltk.Vader)\n",
    "\n",
    "test_tweet = tweets_train['tweet'][14063]\n",
    "label_TB = TextBlob(test_tweet).sentiment\n",
    "label_NB = TextBlob(test_tweet, analyzer=NaiveBayesAnalyzer()).sentiment\n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "total_score = SIA.polarity_scores(test_tweet)\n",
    "print(\"Example tweet: '\"+ str(test_tweet), \"'\")\n",
    "print('Scores using TextBlob default', str(label_TB))\n",
    "print('Scores using TextBlob Naive Bayes classifier', str(label_NB))\n",
    "print('Scores using Vader', str(total_score))\n",
    "# print('Label and negative probability using sentiment API', str(get_sentiment(test_tweet)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:00.391131Z",
     "start_time": "2018-08-20T20:56:35.124438Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding a column for sentiment label and negative score each\n",
    "tweets_train['sentiment_TextBlob'] = [get_TextBlob_sentiment(tweet)[0] for tweet in tweets_train['tweet']]\n",
    "tweets_train['polarity_TextBlob'] = [get_TextBlob_sentiment(tweet)[1] for tweet in tweets_train['tweet']]\n",
    "tweets_train['sentiment_Vader'] = [get_Vader_sentiment(tweet)[0] for tweet in tweets_train['tweet']]\n",
    "tweets_train['polarity_Vader'] = [get_Vader_sentiment(tweet)[1] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['sentiment'] = [get_sentiment(tweet)[0] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['neg_sentiment_prob'] = [get_sentiment(tweet)[1] for tweet in tweets_train['tweet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the discrepancies between TextBlob and Vader approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:00.396422Z",
     "start_time": "2018-08-20T21:00:00.393302Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_train[(tweets_train['sentiment_TextBlob'] == 'positive') & (tweets_train['sentiment_Vader'] == 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:00.401328Z",
     "start_time": "2018-08-20T21:00:00.398780Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_train[(tweets_train['sentiment_Vader'] == 'positive') & (tweets_train['sentiment_TextBlob'] == 'negative')].sort_values(by='polarity_Vader', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:00.404965Z",
     "start_time": "2018-08-20T21:00:00.403159Z"
    }
   },
   "outputs": [],
   "source": [
    "#tweets_train['tweet'][14063]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.403194Z",
     "start_time": "2018-08-20T21:00:00.407419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment_TextBlob</th>\n",
       "      <th>polarity_TextBlob</th>\n",
       "      <th>sentiment_Vader</th>\n",
       "      <th>polarity_Vader</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue's new CEO seeks the right balance to ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.140693</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.2462</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united yes. We waited in line for almost an h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the we got into the gate at IAH on tim...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir its cool that my bags take a bit...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline  retweet_count  \\\n",
       "0      Delta              0   \n",
       "1      Delta              0   \n",
       "2     United              0   \n",
       "3     United              0   \n",
       "4  Southwest              0   \n",
       "\n",
       "                                               tweet sentiment_TextBlob  \\\n",
       "0  @JetBlue's new CEO seeks the right balance to ...            neutral   \n",
       "1  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...           positive   \n",
       "2  @united yes. We waited in line for almost an h...           negative   \n",
       "3  @united the we got into the gate at IAH on tim...           negative   \n",
       "4  @SouthwestAir its cool that my bags take a bit...            neutral   \n",
       "\n",
       "   polarity_TextBlob sentiment_Vader  polarity_Vader sentiment  \n",
       "0           0.140693        positive          0.3182   neutral  \n",
       "1           0.312500        negative         -0.2462  negative  \n",
       "2          -0.125000        positive          0.4019  negative  \n",
       "3          -0.100000         neutral          0.0000  negative  \n",
       "4           0.175000        positive          0.3182   neutral  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentiment = []\n",
    "for row in tweets_train.iterrows():\n",
    "    index = row[0]\n",
    "    if tweets_train['sentiment_TextBlob'][index] == 'negative' or tweets_train['sentiment_Vader'][index] == 'negative':\n",
    "        final_sentiment.append('negative')\n",
    "    elif tweets_train['sentiment_TextBlob'][index] == 'neutral' or tweets_train['sentiment_Vader'][index] == 'neutral':\n",
    "        final_sentiment.append('neutral')\n",
    "    else:\n",
    "        final_sentiment.append('positive')\n",
    "\n",
    "tweets_train['sentiment'] = final_sentiment\n",
    "tweets_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:09:37.926732Z",
     "start_time": "2018-08-20T21:09:37.916285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5192 entries, 1 to 14480\n",
      "Data columns (total 8 columns):\n",
      "airline               5192 non-null object\n",
      "retweet_count         5192 non-null int64\n",
      "tweet                 5192 non-null object\n",
      "sentiment_TextBlob    5192 non-null object\n",
      "polarity_TextBlob     5192 non-null float64\n",
      "sentiment_Vader       5192 non-null object\n",
      "polarity_Vader        5192 non-null float64\n",
      "sentiment             5192 non-null object\n",
      "dtypes: float64(2), int64(1), object(5)\n",
      "memory usage: 365.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Let's filter only on negative tweets (since that is our constructive criticism (or hopefully so))\n",
    "neg_tweets = tweets_train[tweets_train['sentiment'] == 'negative']\n",
    "neg_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:09:49.673679Z",
     "start_time": "2018-08-20T21:09:49.620190Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "neg_tweets.drop(columns=['sentiment_TextBlob', 'polarity_TextBlob', 'sentiment_Vader', 'polarity_Vader'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:09:58.912430Z",
     "start_time": "2018-08-20T21:09:58.903977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united yes. We waited in line for almost an h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the we got into the gate at IAH on tim...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united I like delays less than you because I'...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united, link to current status of flights/air...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline  retweet_count                                              tweet  \\\n",
       "1   Delta              0  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...   \n",
       "2  United              0  @united yes. We waited in line for almost an h...   \n",
       "3  United              0  @united the we got into the gate at IAH on tim...   \n",
       "6  United              0  @united I like delays less than you because I'...   \n",
       "7  United              0  @united, link to current status of flights/air...   \n",
       "\n",
       "  sentiment  \n",
       "1  negative  \n",
       "2  negative  \n",
       "3  negative  \n",
       "6  negative  \n",
       "7  negative  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get sweeping before clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T21:01:51.536234Z",
     "start_time": "2018-08-17T21:01:51.533982Z"
    }
   },
   "source": [
    "#### Examining hashtag containing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.687979Z",
     "start_time": "2018-08-20T20:56:27.541Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Identify all the tweets containing hashtags\n",
    "# pattern2 = re.compile('#[A-Za-z]+\\w')\n",
    "# count_hash_tweets = 0\n",
    "\n",
    "# for index, tweet in enumerate(tweets_train['tweet']):\n",
    "#     try:\n",
    "#         h_tweet = pattern2.search(tweet).group()\n",
    "#         print(index, h_tweet)\n",
    "#         count_hash_tweets += 1\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "# print('\\nTotal number of tweets containing hashtags =', str(count_hash_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same for urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.689089Z",
     "start_time": "2018-08-20T20:56:27.563Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Find url pattern\n",
    "# https_list = []\n",
    "\n",
    "# for tweet in tweets_train['tweet']:\n",
    "#     if url_remove(tweet) == []:\n",
    "#         pass\n",
    "#     else:\n",
    "#         https_list.append(url_remove(tweet))\n",
    "        \n",
    "# print(https_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.690166Z",
     "start_time": "2018-08-20T20:56:27.586Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Testing code_remove function\n",
    "# test_string = tweets_train['tweet'][1582]\n",
    "# print(test_string)\n",
    "# print(url_remove(test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wooohooo!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's location time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.691494Z",
     "start_time": "2018-08-20T20:56:27.606Z"
    }
   },
   "outputs": [],
   "source": [
    "# madrid_tweet = tweets_train['tweet'][14451]\n",
    "# geo = GeoText(madrid_tweet)\n",
    "# geo.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.692704Z",
     "start_time": "2018-08-20T20:56:27.629Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clean up tweet column, remove the \"@word\" from the rest of the tweet\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet'].apply(remove_airline)\n",
    "\n",
    "#Clean up tweet column, remove the hashtags from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_hashtag)\n",
    "\n",
    "#Clean up tweet column, remove code-like elements from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_code)\n",
    "\n",
    "#Clean up tweet column, remove urls from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_url)\n",
    "\n",
    "#Clean up tweet column, remove locations from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_location)\n",
    "\n",
    "#Clean up tweet column, remove month names from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_month)\n",
    "\n",
    "#Clean up tweet column, remove emojis from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_emoji)\n",
    "\n",
    "#Clean up tweet column, remove airport codes and names from all tweets\n",
    "tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_airport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini moment of truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.693864Z",
     "start_time": "2018-08-20T20:56:27.653Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Let's make sure it works (indexes to test = 1, 3, 1582, 12805, 14451)\n",
    "print(tweets_train['tweet'][1], '\\n')\n",
    "print(tweets_train['tweet_clean'][1], '\\n')\n",
    "\n",
    "print(tweets_train['tweet'][3], '\\n')\n",
    "print(tweets_train['tweet_clean'][3], '\\n')\n",
    "\n",
    "print(tweets_train['tweet'][1582], '\\n')\n",
    "print(tweets_train['tweet_clean'][1582], '\\n')\n",
    "\n",
    "print(tweets_train['tweet'][12805], '\\n')\n",
    "print(tweets_train['tweet_clean'][12805], '\\n')\n",
    "\n",
    "print(tweets_train['tweet'][14451], '\\n')\n",
    "print(tweets_train['tweet_clean'][14451], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.695140Z",
     "start_time": "2018-08-20T20:56:27.675Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-20T21:00:01.421905Z",
     "start_time": "2018-08-20T21:00:01.405201Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pickle the dataset, just in case \n",
    "with open('negative_tweets.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(tweets_train, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
