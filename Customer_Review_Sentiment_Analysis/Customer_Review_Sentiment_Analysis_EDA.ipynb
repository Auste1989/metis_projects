{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration, Cleanup and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:16.523727Z",
     "start_time": "2018-08-22T04:17:16.512220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.497476Z",
     "start_time": "2018-08-22T04:17:16.525612Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#SQL related\n",
    "import sqlite3\n",
    "import pandas.io.sql as pd_sql\n",
    "\n",
    "#API related\n",
    "import requests\n",
    "\n",
    "#Preprocessing\n",
    "import re\n",
    "from geotext import GeoText\n",
    "from calendar import month_name\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#Sentiment analysis\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.502039Z",
     "start_time": "2018-08-22T04:17:17.499581Z"
    }
   },
   "outputs": [],
   "source": [
    "#'/Users/auste_m/ds/metis/metisgh/github/metis_projects/Customer_Review_Sentiment_Analysis/Datasets/twitter-airline-sentiment/database.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.506898Z",
     "start_time": "2018-08-22T04:17:17.503917Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting up for working with SQLite database\n",
    "sqlite_file = './Datasets/twitter-airline-sentiment/database.sqlite'\n",
    "\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.513253Z",
     "start_time": "2018-08-22T04:17:17.508675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns of the table are: \n",
      "['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline', 'airline_sentiment_gold', 'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord', 'tweet_created', 'tweet_location', 'user_timezone']\n",
      "\n",
      "Preview of one of the rows in the table:\n",
      "(567588278875213824, 'neutral', 1, '', '', 'Delta', '', 'JetBlueNews', '', 0, \"@JetBlue's new CEO seeks the right balance to please passengers and Wall ... - Greenfield Daily Reporter http://t.co/LM3opxkxch\", '', '2015-02-16 23:36:05 -0800', 'USA', 'Sydney')\n"
     ]
    }
   ],
   "source": [
    "#Check one of the rows in the table\n",
    "preview = cursor.execute(\"SELECT * FROM Tweets LIMIT 20\")\n",
    "columns = [column[0] for column in preview.description]\n",
    "print('The columns of the table are:' + ' \\n' + str(columns) + '\\n')\n",
    "print('Preview of one of the rows in the table:' + '\\n' + str(preview.fetchone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.633884Z",
     "start_time": "2018-08-22T04:17:17.515092Z"
    }
   },
   "outputs": [],
   "source": [
    "#Retrieve relevant information from Tweets table in SQLite database and store them in a pandas dataframe\n",
    "query = \"\"\"SELECT airline, retweet_count, text as 'tweet' \n",
    "            FROM Tweets\"\"\"\n",
    "\n",
    "tweets_df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.660296Z",
     "start_time": "2018-08-22T04:17:17.635989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14485 entries, 0 to 14484\n",
      "Data columns (total 3 columns):\n",
      "airline          14485 non-null object\n",
      "retweet_count    14485 non-null int64\n",
      "tweet            14485 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 339.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue's new CEO seeks the right balance to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united yes. We waited in line for almost an h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the we got into the gate at IAH on tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir its cool that my bags take a bit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     airline  retweet_count                                              tweet\n",
       "0      Delta              0  @JetBlue's new CEO seeks the right balance to ...\n",
       "1      Delta              0  @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...\n",
       "2     United              0  @united yes. We waited in line for almost an h...\n",
       "3     United              0  @united the we got into the gate at IAH on tim...\n",
       "4  Southwest              0  @SouthwestAir its cool that my bags take a bit..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "print(tweets_df.info())\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put aside a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.669535Z",
     "start_time": "2018-08-22T04:17:17.662121Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_test = tweets_df[10000:12000]\n",
    "tweets_train = tweets_df[:10000]\n",
    "tweets_train = tweets_train.append(tweets_df[12000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.675789Z",
     "start_time": "2018-08-22T04:17:17.671547Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('tweets_test.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(tweets_test, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:17.679579Z",
     "start_time": "2018-08-22T04:17:17.677267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tweets_train.info()\n",
    "# tweets_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's gather airport information from an external API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:19.738403Z",
     "start_time": "2018-08-22T04:17:17.682023Z"
    }
   },
   "outputs": [],
   "source": [
    "#First need to get global airport database through an API request \n",
    "airport_db_url = 'https://aviation-edge.com/api/public/airportDatabase?key=42e87b-a2f1be-c446fa-06d7a2-012f14'\n",
    "get_response = requests.get(airport_db_url)\n",
    "airport_db = get_response.json()\n",
    "\n",
    "#Then I need to extract the information that is relevant to me (airport names and codes)\n",
    "airport_info = []\n",
    "\n",
    "for airport in airport_db:\n",
    "    airport_info.append(airport['codeIataAirport'])\n",
    "    airport_info.append(airport['nameAirport'])\n",
    "\n",
    "#Test that results make sense\n",
    "# if 'IAH' in airport_codes:\n",
    "#     print(airport_db[airport_codes.index('IAH')])\n",
    "# else:\n",
    "#     print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:19.743755Z",
     "start_time": "2018-08-22T04:17:19.740321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airport_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's set up some helped functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:19.764155Z",
     "start_time": "2018-08-22T04:17:19.746391Z"
    }
   },
   "outputs": [],
   "source": [
    "#helper function to remove stuff from tweets\n",
    "\n",
    "def remove_airline(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with hashtag removed.\"\"\"\n",
    "    pattern1 = re.compile('@[A-Za-z]+\\w')\n",
    "    new_string = string\n",
    "    try:\n",
    "        all_airlines = pattern1.findall(new_string)\n",
    "        for airline in all_airlines:\n",
    "            new_string = re.sub(airline, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "def remove_hashtag(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with hashtag removed.\"\"\"\n",
    "    pattern2 = re.compile('#\\w+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        all_hashtags = pattern2.findall(new_string)\n",
    "        for hashtag in all_hashtags:\n",
    "            new_string = re.sub(hashtag, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_code(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with any capital letter & digit combination text removed.\"\"\"\n",
    "    pattern3 = re.compile('[A-Z]?\\d+[A-Z]+')\n",
    "    pattern4 = re.compile('\\d+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        codes = pattern3.findall(new_string)\n",
    "        codes.extend(pattern4.findall(new_string))\n",
    "        for elem in codes:\n",
    "            new_string = re.sub(elem, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "    \n",
    "    \n",
    "def remove_url(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns the same string with any urls removed removed.\"\"\"\n",
    "    pattern5 = re.compile('http://t.co/\\w+')\n",
    "    new_string = string\n",
    "    try:\n",
    "        urls = pattern5.findall(new_string)\n",
    "        for url in urls:\n",
    "            new_string = re.sub(url, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_location(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with location information removed.\"\"\"\n",
    "    new_string = string\n",
    "    geo_loc = GeoText(string)\n",
    "    locations = []\n",
    "    if geo_loc.cities != []:\n",
    "        locations.extend(geo_loc.cities)\n",
    "    if geo_loc.countries != []:\n",
    "        locations.extend(geo_loc.countries)\n",
    "    try:\n",
    "        for loc in locations:\n",
    "            new_string = re.sub(loc, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "    \n",
    "    \n",
    "def remove_month(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with month information removed.\"\"\"\n",
    "    new_string = string\n",
    "    all_months = month_name[1:]\n",
    "    try:\n",
    "        for word in string.split():\n",
    "            if word in all_months:\n",
    "                new_string = re.sub(word, '', new_string)\n",
    "            else:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def remove_emoji(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with emojis removed.\"\"\"    \n",
    "    pattern6 = re.compile(\"[\"\n",
    "                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    new_string = string\n",
    "    try:\n",
    "        emojis = pattern6.findall(new_string)\n",
    "        for emoji in emojis:\n",
    "            new_string = re.sub(emoji, '', new_string)\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "def remove_airport(string):\n",
    "    \"\"\"Takes a string as input.\n",
    "    Returns a new string with airport codes removed.\"\"\" \n",
    "    new_string = string\n",
    "    try:\n",
    "        for word in string.split():\n",
    "            if word in airport_info:\n",
    "                new_string = re.sub(word, '', new_string)\n",
    "            else:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    return new_string\n",
    "\n",
    "\n",
    "\n",
    "def get_clean_tweet(string):\n",
    "    \"\"\"Takes a string and uses all the cleaning related functions above to remove unnecessary elements.\n",
    "    Returns a 'clean' string.\"\"\"\n",
    "    clean_string = remove_airline(remove_hashtag(remove_code(remove_url(remove_location(remove_month(remove_emoji(remove_airport(string))))))))\n",
    "    return clean_string\n",
    "\n",
    "\n",
    "def get_Vader_sentiment(string):\n",
    "    \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "    Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "    SIA = SentimentIntensityAnalyzer()\n",
    "    total_score = SIA.polarity_scores(string)\n",
    "    if total_score['compound'] < -0.05:\n",
    "        sentiment = 'negative'\n",
    "    elif total_score['compound'] >= 0.2:\n",
    "        sentiment = 'positive'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    polarity = total_score['compound']\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "def get_TextBlob_sentiment(string):\n",
    "    \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "    Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "    sentiment_all = TextBlob(string).sentiment\n",
    "    if sentiment_all.polarity < -0.05:\n",
    "        sentiment = 'negative'\n",
    "    elif sentiment_all.polarity >= 0.2:\n",
    "        sentiment = 'positive'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    polarity = sentiment_all.polarity\n",
    "    return sentiment\n",
    "\n",
    "def get_sentiment(string):\n",
    "    \"\"\"Takes a string, generates sentiment using TextBlob and Vader.\n",
    "    Returns the final sentiment label based on the two techniques (negative in either => negative)\"\"\"\n",
    "    sentiment_blob = get_TextBlob_sentiment(string)\n",
    "    sentiment_vader = get_Vader_sentiment(string)\n",
    "    sentiment = ''\n",
    "    if sentiment_blob == 'negative' or sentiment_vader == 'negative':\n",
    "        sentiment = 'negative'\n",
    "    elif sentiment_blob == 'neutral' or sentiment_vader == 'neutral':\n",
    "        sentiment = 'neutral'\n",
    "    else:\n",
    "        sentiment = 'positive'\n",
    "    return sentiment\n",
    "\n",
    "# def get_sentiment_API(string):\n",
    "#     \"\"\"Takes a string as input. Uses text processing mashape API to retrieve the sentiment.\n",
    "#     Returns a sentiment label and score (from -1 to 1, negatives signalling negative sentiment).\"\"\" \n",
    "#     #API stuff\n",
    "#     sentiment_API_url = 'https://japerk-text-processing.p.mashape.com/sentiment/'\n",
    "#     sentiment_API_response = requests.post(sentiment_API_url,\n",
    "#                                           data={\n",
    "#                                             \"language\": \"english\",\n",
    "#                                             \"text\": test_tweet}\n",
    "#                                               ,\n",
    "#                                           headers={\n",
    "#                                             \"X-Mashape-Key\": \"3hN4k8H8Brmsh0Hp4sTefboY6vHpp1qZZ3jjsnvlGiMsNSK59o\",\n",
    "#                                             \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
    "#                                             \"Accept\": \"application/json\"}\n",
    "#                                           )\n",
    "\n",
    "#     sentiment_all = sentiment_API_response.json()\n",
    "#     sentiment = sentiment_all['label']\n",
    "#     neg_prob = sentiment_all['probability']['neg']\n",
    "#     return (sentiment, neg_prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:24.382798Z",
     "start_time": "2018-08-22T04:17:19.766713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example tweet: '@SouthwestAir need to learn how to treat people with respect and just a little dignity. #FAIL '\n",
      "Scores using TextBlob default Sentiment(polarity=-0.34375, subjectivity=0.39999999999999997)\n",
      "Scores using TextBlob Naive Bayes classifier Sentiment(classification='pos', p_pos=0.7744402760303103, p_neg=0.22555972396969037)\n",
      "Scores using Vader {'neg': 0.0, 'neu': 0.594, 'pos': 0.406, 'compound': 0.8024}\n"
     ]
    }
   ],
   "source": [
    "#Are the tweets positive or negative (tried TextBlob.sentiment, TextBlob.NaiveBayesAnalyzer, nltk.Vader, API sentiment analyzer)\n",
    "\n",
    "test_tweet = tweets_train['tweet'][14063]\n",
    "label_TB = TextBlob(test_tweet).sentiment\n",
    "label_NB = TextBlob(test_tweet, analyzer=NaiveBayesAnalyzer()).sentiment\n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "total_score = SIA.polarity_scores(test_tweet)\n",
    "print(\"Example tweet: '\"+ str(test_tweet), \"'\")\n",
    "print('Scores using TextBlob default', str(label_TB))\n",
    "print('Scores using TextBlob Naive Bayes classifier', str(label_NB))\n",
    "print('Scores using Vader', str(total_score))\n",
    "# print('Label and negative probability using sentiment API', str(get_sentiment_API(test_tweet)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the discrepancies between TextBlob and Vader approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:24.387867Z",
     "start_time": "2018-08-22T04:17:24.385071Z"
    }
   },
   "outputs": [],
   "source": [
    "#Testing different approaches\n",
    "# tweets_train['sentiment_TextBlob'] = [get_TextBlob_sentiment(tweet)[0] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['polarity_TextBlob'] = [get_TextBlob_sentiment(tweet)[1] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['sentiment_Vader'] = [get_Vader_sentiment(tweet)[0] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['polarity_Vader'] = [get_Vader_sentiment(tweet)[1] for tweet in tweets_train['tweet']]\n",
    "# tweets_train['sentiment'] = [get_sentiment_API(tweet)[0] for tweet in tweets_train['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:24.391832Z",
     "start_time": "2018-08-22T04:17:24.389790Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_train[(tweets_train['sentiment_TextBlob'] == 'positive') & (tweets_train['sentiment_Vader'] == 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:24.396676Z",
     "start_time": "2018-08-22T04:17:24.393932Z"
    }
   },
   "outputs": [],
   "source": [
    "# tweets_train[(tweets_train['sentiment_Vader'] == 'positive') & (tweets_train['sentiment_TextBlob'] == 'negative')].sort_values(by='polarity_Vader', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:17:24.400933Z",
     "start_time": "2018-08-22T04:17:24.398822Z"
    }
   },
   "outputs": [],
   "source": [
    "#tweets_train['tweet'][14063]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.912986Z",
     "start_time": "2018-08-22T04:17:24.402947Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding a column for sentiment label and negative score each\n",
    "tweets_train['sentiment'] = [get_sentiment(tweet) for tweet in tweets_train['tweet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm only really interested in negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.927724Z",
     "start_time": "2018-08-22T04:19:07.914944Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5192 entries, 1 to 14480\n",
      "Data columns (total 4 columns):\n",
      "airline          5192 non-null object\n",
      "retweet_count    5192 non-null int64\n",
      "tweet            5192 non-null object\n",
      "sentiment        5192 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 202.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Let's filter only on negative tweets (since that is our constructive criticism (or hopefully so))\n",
    "neg_tweets = tweets_train[tweets_train['sentiment'] == 'negative']\n",
    "neg_tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get sweeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-17T21:01:51.536234Z",
     "start_time": "2018-08-17T21:01:51.533982Z"
    }
   },
   "source": [
    "#### Examining hashtag containing tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.933202Z",
     "start_time": "2018-08-22T04:19:07.930214Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Identify all the tweets containing hashtags\n",
    "# pattern2 = re.compile('#[A-Za-z]+\\w')\n",
    "# count_hash_tweets = 0\n",
    "\n",
    "# for index, tweet in enumerate(tweets_train['tweet']):\n",
    "#     try:\n",
    "#         h_tweet = pattern2.search(tweet).group()\n",
    "#         print(index, h_tweet)\n",
    "#         count_hash_tweets += 1\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "# print('\\nTotal number of tweets containing hashtags =', str(count_hash_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same for urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.939323Z",
     "start_time": "2018-08-22T04:19:07.935905Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Find url pattern\n",
    "# https_list = []\n",
    "\n",
    "# for tweet in tweets_train['tweet']:\n",
    "#     if url_remove(tweet) == []:\n",
    "#         pass\n",
    "#     else:\n",
    "#         https_list.append(url_remove(tweet))\n",
    "        \n",
    "# print(https_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.944941Z",
     "start_time": "2018-08-22T04:19:07.942079Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Testing code_remove function\n",
    "# test_string = tweets_train['tweet'][1582]\n",
    "# print(test_string)\n",
    "# print(url_remove(test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wooohooo!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now it's location time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.950368Z",
     "start_time": "2018-08-22T04:19:07.947557Z"
    }
   },
   "outputs": [],
   "source": [
    "# madrid_tweet = tweets_train['tweet'][14451]\n",
    "# geo = GeoText(madrid_tweet)\n",
    "# geo.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:07.956249Z",
     "start_time": "2018-08-22T04:19:07.952863Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Clean up tweet column, remove the \"@word\" from the rest of the tweet\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet'].apply(remove_airline)\n",
    "\n",
    "# #Clean up tweet column, remove the hashtags from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_hashtag)\n",
    "\n",
    "# #Clean up tweet column, remove code-like elements from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_code)\n",
    "\n",
    "# #Clean up tweet column, remove urls from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_url)\n",
    "\n",
    "# #Clean up tweet column, remove locations from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_location)\n",
    "\n",
    "# #Clean up tweet column, remove month names from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_month)\n",
    "\n",
    "# #Clean up tweet column, remove emojis from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_emoji)\n",
    "\n",
    "# #Clean up tweet column, remove airport codes and names from all tweets\n",
    "# tweets_train['tweet_clean'] = tweets_train['tweet_clean'].apply(remove_airport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:35.617375Z",
     "start_time": "2018-08-22T04:19:07.958028Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Clean up tweet column, remove codes, hashtags, airline names, urls, locations, etc.\n",
    "neg_tweets['tweet_clean'] = neg_tweets['tweet'].apply(get_clean_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mini moment of truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:35.624978Z",
     "start_time": "2018-08-22T04:19:35.619587Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ #nothappy \n",
      "\n",
      " is REALLY getting on my nerves !!   \n",
      "\n",
      "@united the we got into the gate at IAH on time and have given our seats and closed the flight. If you know people is arriving, have to wait \n",
      "\n",
      " the we got into the gate at  on time and have given our seats and closed the flight. If you know people is arriving, have to wait \n",
      "\n",
      "@united lots of reports of system failures delaying flights over the last week. Currently sitting on the tarmac at OGG for over an hour. \n",
      "\n",
      " lots of reports of system failures delaying flights over the last week. Currently sitting on the tarmac at  for over an hour. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's make sure it works (indexes to test = 1, 3, 12805)\n",
    "print(neg_tweets['tweet'][1], '\\n')\n",
    "print(neg_tweets['tweet_clean'][1], '\\n')\n",
    "\n",
    "print(neg_tweets['tweet'][3], '\\n')\n",
    "print(neg_tweets['tweet_clean'][3], '\\n')\n",
    "\n",
    "print(neg_tweets['tweet'][12805], '\\n')\n",
    "print(neg_tweets['tweet_clean'][12805], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:35.647627Z",
     "start_time": "2018-08-22T04:19:35.628435Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>is REALLY getting on my nerves !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united yes. We waited in line for almost an h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>yes. We waited in line for almost an hour to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the we got into the gate at IAH on tim...</td>\n",
       "      <td>negative</td>\n",
       "      <td>the we got into the gate at  on time and have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united I like delays less than you because I'...</td>\n",
       "      <td>negative</td>\n",
       "      <td>I like delays less than you because I'm the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united, link to current status of flights/air...</td>\n",
       "      <td>negative</td>\n",
       "      <td>, link to current status of flights/airports? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united I tried 2 DM it would not go thru... n...</td>\n",
       "      <td>negative</td>\n",
       "      <td>I tried  DM it would not go thru... not sure why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@united i have items of sentimental value that...</td>\n",
       "      <td>negative</td>\n",
       "      <td>i have items of sentimental value that I'm he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir We have been stuck in SJU for se...</td>\n",
       "      <td>negative</td>\n",
       "      <td>We have been stuck in  for several hours and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>United</td>\n",
       "      <td>0</td>\n",
       "      <td>@United is officially the worst, most delayed,...</td>\n",
       "      <td>negative</td>\n",
       "      <td>is officially the worst, most delayed, and le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Southwest</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir won't answer their phones #Horri...</td>\n",
       "      <td>negative</td>\n",
       "      <td>won't answer their phones</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline  retweet_count  \\\n",
       "1       Delta              0   \n",
       "2      United              0   \n",
       "3      United              0   \n",
       "6      United              0   \n",
       "7      United              0   \n",
       "9      United              0   \n",
       "16     United              0   \n",
       "17  Southwest              0   \n",
       "21     United              0   \n",
       "22  Southwest              0   \n",
       "\n",
       "                                                tweet sentiment  \\\n",
       "1   @JetBlue is REALLY getting on my nerves !! ðŸ˜¡ðŸ˜¡ ...  negative   \n",
       "2   @united yes. We waited in line for almost an h...  negative   \n",
       "3   @united the we got into the gate at IAH on tim...  negative   \n",
       "6   @united I like delays less than you because I'...  negative   \n",
       "7   @united, link to current status of flights/air...  negative   \n",
       "9   @united I tried 2 DM it would not go thru... n...  negative   \n",
       "16  @united i have items of sentimental value that...  negative   \n",
       "17  @SouthwestAir We have been stuck in SJU for se...  negative   \n",
       "21  @United is officially the worst, most delayed,...  negative   \n",
       "22  @SouthwestAir won't answer their phones #Horri...  negative   \n",
       "\n",
       "                                          tweet_clean  \n",
       "1                 is REALLY getting on my nerves !!    \n",
       "2    yes. We waited in line for almost an hour to ...  \n",
       "3    the we got into the gate at  on time and have...  \n",
       "6    I like delays less than you because I'm the o...  \n",
       "7   , link to current status of flights/airports? ...  \n",
       "9    I tried  DM it would not go thru... not sure why  \n",
       "16   i have items of sentimental value that I'm he...  \n",
       "17   We have been stuck in  for several hours and ...  \n",
       "21   is officially the worst, most delayed, and le...  \n",
       "22                      won't answer their phones      "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving (just in case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-22T04:19:35.661203Z",
     "start_time": "2018-08-22T04:19:35.650072Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pickle the dataset, just in case \n",
    "with open('negative_tweets.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(neg_tweets, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
